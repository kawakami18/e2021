{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "深層学習day3_深層学習day4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPJ45Pjqns7rgCLcxchU3iZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kawakami18/e2021/blob/main/%E6%B7%B1%E5%B1%A4%E5%AD%A6%E7%BF%92day3_%E6%B7%B1%E5%B1%A4%E5%AD%A6%E7%BF%92day4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNfcp9tMA-vk"
      },
      "source": [
        "# **深層学習day3**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOath6LzBLjO"
      },
      "source": [
        "# Section1:再起型ニューラルネットワークの概念"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mO09t3hHBdue"
      },
      "source": [
        "**まとめ**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaKL1B8YL4Kl"
      },
      "source": [
        "RNN(再起型ニューラルネットワーク)時系列データに対応可能な、ニューラルネットワークのこと。\n",
        "\n",
        "時系列データとは時間的順序をおって一定間隔ごとに観察され、しかも相互に統計的依存関係が認められるようなデータの系列。例えば、音声データや、テキストデータなど。\n",
        "\n",
        "数学的記述コード\n",
        "\n",
        "u[:, t + 1] = np.dot(X, W_in) + np.dot(z[:, t].reshape(1, -1), W)\n",
        "\n",
        "z[:, t + 1] = functions.sigmoid(u[:, t + 1])\n",
        "\n",
        "np.dot(z[:, t + 1].reshape(1, -1), W_out)\n",
        "\n",
        "y[:, t] = functions.sigmoid(np.dot(z[:, t + 1].reshape(1, -1), W_out))\n",
        "\n",
        "RNNの特徴は時系列モデルを扱うとき、初期の状態と過去の時間(ｔ-1)の状態を保持し、そこから次の時間でt\n",
        "を再帰的に求める再帰構造が必要になる。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HmDomtETQ09"
      },
      "source": [
        "**実装演習結果**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "WXuqNSYQTVV4",
        "outputId": "8a29f144-c37a-48ae-d64a-047cf3146815"
      },
      "source": [
        "\"\"\"\n",
        "# バイナリ加算\n",
        "import numpy as np\n",
        "from common import functions\n",
        "import matplorlib.pyplot as plt\n",
        "\n",
        "def d_tanh(x):\n",
        "    return 1/(np.cosh(x) ** 2)\n",
        "\n",
        "# データを用意\n",
        "# 2進数の桁数\n",
        "binary_dim = 8\n",
        "# 最大値\n",
        "largest_number = pow(2, binary_dim)\n",
        "# largest_numberまで2進数を用意\n",
        "binary = np.unpackbits(np.array([range(largest_number)], dtype, uint8), T, axis=1)\n",
        "\n",
        "input_layer_size = 2\n",
        "hidden_layer_size = 16\n",
        "output_layer_size = 1\n",
        "\n",
        "weight_init_std = 1\n",
        "learning_rate = 0.1\n",
        "\n",
        "iters_num = 10000\n",
        "plot_interval = 100\n",
        "\n",
        "# ウェイト初期化(バイアスは簡単のため省略)\n",
        "W_in = weight_init_std * np.random.randn(input_layer_size, hidden_layer_size)\n",
        "W_out = weight_init_std * np.random.randn(hidden_layer_size, output_layer_size)\n",
        "W = weight_init_std * np.random.randn(hidden_layer_size, hidden_layer_size)\n",
        "\n",
        "# 勾配\n",
        "W_in_grad = np.zeros_like(W_in)\n",
        "W_out_grad = np.zeros_like(W_out)\n",
        "W_grad = np.zeros_like(W)\n",
        "\n",
        "u = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "z = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "\n",
        "delta_out = np.zeros((out_layer_size, binary_dim))\n",
        "dalta = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "\n",
        "all_losses = []\n",
        "\n",
        "for i in range(iters_num):\n",
        "\n",
        "    # A, B初期化(a + b = d)\n",
        "    a_int = np.random.randint(largest_number/2)\n",
        "    a_bin = binary[b_int] # binary encoding\n",
        "\n",
        "    # 正解データ\n",
        "    d_int = a_int + b_int\n",
        "    d_bin = binary[d_int]\n",
        "\n",
        "    # 出力バイナリ\n",
        "    out_bin = np.zeros_like(d_bin)\n",
        "\n",
        "    # 時系列全体の誤差\n",
        "    all_loss = 0\n",
        "\n",
        "    # 時系列ループ\n",
        "    for t in range(binary_dim):\n",
        "        # 入力値\n",
        "        X = np.array([a_bin[ - t - 1], b_bin[ - t - 1]]).reshape(1, -1)\n",
        "        # 時系列ｔにおける正解データ\n",
        "        dd = np.array([d_bin[binary_dim - t - 1]])\n",
        "\n",
        "        u[:, t+1] = np.dot(X, W_in) + np.dot(z[:, t].reshape(1, -1), W)\n",
        "        z[:, t+1] = functions.sigmoid(u[:, t+1])\n",
        "        y[:, t] = runctions.sigmoid(np.dot(z[:, t+1].reshape(1, -1), W_out))\n",
        "\n",
        "        # 誤差\n",
        "        loss = functions.mean_squared_error(dd, y[:, t])\n",
        "\n",
        "    for t in range(binary_dim)[:: -1]:\n",
        "        X = np.array([a_bin[-t-1]]).reshape(1, -1)\n",
        "\n",
        "        delta[:, t] = (np.dot(delta[:, t+1].T, W.T) + np.dot(delta_out[:, t].T, W_out.T)) * functions.d_sigmoid(u[:, t+1])\n",
        "\n",
        "        # 勾配更新\n",
        "        W_out_grad += np.dot(z[:, t+1].reshape(-1, 1), delta_out[:, t].reshape(-1, 1)) \n",
        "        W_grad += np.dot(z[:, t].reshape(-1, 1), delta[:, t].reshape(-1, 1))\n",
        "        W_in_grad += np.dot(X.T, delta[:, t].reshape(1, -1))\n",
        "\n",
        "    # 勾配適用\n",
        "    W_in -= learning_rate * W_in_grad\n",
        "    W_out -= learning_rate * W_out_grad\n",
        "    W -= learning_rate * W_grad\n",
        "\n",
        "    W_in_grad *= 0\n",
        "    W_out_grad *= 0\n",
        "    W_grad *= 0\n",
        "\n",
        "    if(i % plot_interval == 0):\n",
        "        all_losses.append(all_loss)\n",
        "        print(\"iters:\" + str(i))\n",
        "        print(\"Loss:\" + str(all_loss))\n",
        "        print(\"Pred:\" + str(out_bin))\n",
        "        print(\"True:\" + str(d_bin))\n",
        "        out_int = 0\n",
        "        for index, x in enumerate(reversed(out_bin)):\n",
        "            out_int += x * pow(2, index)\n",
        "        print(str(a_int) + \" + \" + str(b_int) + \" = \" + str(out_int))\n",
        "        print(\"- - - - - - - - - - \")\n",
        "\n",
        "lists = range(0, iters_num, plot_interval)\n",
        "plt.plot(lists, all_losses, label = \"loss\")\n",
        "plt.show()\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n# バイナリ加算\\nimport numpy as np\\nfrom common import functions\\nimport matplorlib.pyplot as plt\\n\\ndef d_tanh(x):\\n    return 1/(np.cosh(x) ** 2)\\n\\n# データを用意\\n# 2進数の桁数\\nbinary_dim = 8\\n# 最大値\\nlargest_number = pow(2, binary_dim)\\n# largest_numberまで2進数を用意\\nbinary = np.unpackbits(np.array([range(largest_number)], dtype, uint8), T, axis=1)\\n\\ninput_layer_size = 2\\nhidden_layer_size = 16\\noutput_layer_size = 1\\n\\nweight_init_std = 1\\nlearning_rate = 0.1\\n\\niters_num = 10000\\nplot_interval = 100\\n\\n# ウェイト初期化(バイアスは簡単のため省略)\\nW_in = weight_init_std * np.random.randn(input_layer_size, hidden_layer_size)\\nW_out = weight_init_std * np.random.randn(hidden_layer_size, output_layer_size)\\nW = weight_init_std * np.random.randn(hidden_layer_size, hidden_layer_size)\\n\\n# 勾配\\nW_in_grad = np.zeros_like(W_in)\\nW_out_grad = np.zeros_like(W_out)\\nW_grad = np.zeros_like(W)\\n\\nu = np.zeros((hidden_layer_size, binary_dim + 1))\\nz = np.zeros((hidden_layer_size, binary_dim + 1))\\n\\ndelta_out = np.zeros((out_layer_size, binary_dim))\\ndalta = np.zeros((hidden_layer_size, binary_dim + 1))\\n\\nall_losses = []\\n\\nfor i in range(iters_num):\\n\\n    # A, B初期化(a + b = d)\\n    a_int = np.random.randint(largest_number/2)\\n    a_bin = binary[b_int] # binary encoding\\n\\n    # 正解データ\\n    d_int = a_int + b_int\\n    d_bin = binary[d_int]\\n\\n    # 出力バイナリ\\n    out_bin = np.zeros_like(d_bin)\\n\\n    # 時系列全体の誤差\\n    all_loss = 0\\n\\n    # 時系列ループ\\n    for t in range(binary_dim):\\n        # 入力値\\n        X = np.array([a_bin[ - t - 1], b_bin[ - t - 1]]).reshape(1, -1)\\n        # 時系列ｔにおける正解データ\\n        dd = np.array([d_bin[binary_dim - t - 1]])\\n\\n        u[:, t+1] = np.dot(X, W_in) + np.dot(z[:, t].reshape(1, -1), W)\\n        z[:, t+1] = functions.sigmoid(u[:, t+1])\\n        y[:, t] = runctions.sigmoid(np.dot(z[:, t+1].reshape(1, -1), W_out))\\n\\n        # 誤差\\n        loss = functions.mean_squared_error(dd, y[:, t])\\n\\n    for t in range(binary_dim)[:: -1]:\\n        X = np.array([a_bin[-t-1]]).reshape(1, -1)\\n\\n        delta[:, t] = (np.dot(delta[:, t+1].T, W.T) + np.dot(delta_out[:, t].T, W_out.T)) * functions.d_sigmoid(u[:, t+1])\\n\\n        # 勾配更新\\n        W_out_grad += np.dot(z[:, t+1].reshape(-1, 1), delta_out[:, t].reshape(-1, 1)) \\n        W_grad += np.dot(z[:, t].reshape(-1, 1), delta[:, t].reshape(-1, 1))\\n        W_in_grad += np.dot(X.T, delta[:, t].reshape(1, -1))\\n\\n    # 勾配適用\\n    W_in -= learning_rate * W_in_grad\\n    W_out -= learning_rate * W_out_grad\\n    W -= learning_rate * W_grad\\n\\n    W_in_grad *= 0\\n    W_out_grad *= 0\\n    W_grad *= 0\\n\\n    if(i % plot_interval == 0):\\n        all_losses.append(all_loss)\\n        print(\"iters:\" + str(i))\\n        print(\"Loss:\" + str(all_loss))\\n        print(\"Pred:\" + str(out_bin))\\n        print(\"True:\" + str(d_bin))\\n        out_int = 0\\n        for index, x in enumerate(reversed(out_bin)):\\n            out_int += x * pow(2, index)\\n        print(str(a_int) + \" + \" + str(b_int) + \" = \" + str(out_int))\\n        print(\"- - - - - - - - - - \")\\n\\nlists = range(0, iters_num, plot_interval)\\nplt.plot(lists, all_losses, label = \"loss\")\\nplt.show()\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0EEFs08O909"
      },
      "source": [
        "**確認テスト**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCfoT4bcRY75"
      },
      "source": [
        "def traverse(node):\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    node: tree node, recursive dict, {left: node', right: node' '}\n",
        "          \n",
        "          if leaf, word embeded vector, (embed_size,)\n",
        "    \n",
        "    W: weights, global variable, (embed_size, 2*embed_size)\n",
        "    \n",
        "    b: bias, global variable, (embed_size,)\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    if not isinstance(node, dict):\n",
        "        \n",
        "        v = node\n",
        "    \n",
        "    else:\n",
        "        \n",
        "        left = traverse(node['left'])\n",
        "        \n",
        "        right = traverse(node['right'])\n",
        "        \n",
        "        v = _acitivation( (ク) )\n",
        "    \n",
        "    rerurn v\n",
        "\n",
        "(ク)・・・W.dot(np.concatenate([left, right])\n",
        "\n",
        "解説\n",
        "\n",
        "隣接単語(表現ベクトル)から表現ベクトルを作るという処理は、隣接している表現leftとrightを合わせたものを特徴量としてそこに重みをかけることで実現する。つまり、W.dot(np.concatenate([left, right])である。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7Q5obfVwyB3"
      },
      "source": [
        "def bptt(xs, ys, W, U, V):\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    ys: labels, (batch_size, n_seq, output_size)\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    hiddens, outputs = rnn_net(xs, W, U, V)\n",
        "\n",
        "    dW = np.zeros_like(W)\n",
        "\n",
        "    dU = np.zeros_like(U)\n",
        "\n",
        "    dV = np.zeros_like(V)\n",
        "\n",
        "    do = _calculate_do(outputs, ys)\n",
        "\n",
        "    batch_size, n_seq = ys.shape[:2]\n",
        "\n",
        "    for t in reversed(range(n_seq)):\n",
        "    \n",
        "        dV += np.dot(do[:, t].T, hiddens[:, t]) / batch_size\n",
        "\n",
        "        delta_t = do[:, t].dot(V)\n",
        "\n",
        "        for bptt_step in reversed(range(t+1)):\n",
        "\n",
        "        dW += np.dot(delta_t.T, xs[:, bptt_step]) / batch_size\n",
        "\n",
        "        dU += np.dot(delta_t.T, hiddens[:, bptt_step-1]) / batch_size\n",
        "\n",
        "        delta_t = (お)\n",
        "\n",
        "    return dW, dU, dV\n",
        "\n",
        "\n",
        "(お)・・・delta_t.dot(U)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31cdodHx0Q6L"
      },
      "source": [
        "**参考記事**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDTRLyR9S45K"
      },
      "source": [
        "# 再起型ニューラルネットワークの順伝播計算\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "\n",
        "class RNN:\n",
        "    def__init__(self, Wx, Wh, h0):\n",
        "        \n",
        "        Wx : 入力ｘにかかる重み(1,隠れ層のノード数)\n",
        "        Wh : 1時刻前のhにかかる重み(隠れ層のノード数,隠れ層のノード数)\n",
        "        h0 : 隠れ層の初期値(1,隠れ層のノードの数)\n",
        "\n",
        "        # パラメータのリスト\n",
        "        self.params = [Wx, Wh]\n",
        "\n",
        "        # 隠れ層の初期値を設定\n",
        "        self.h_prev = (あ)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # 順伝播計算\n",
        "        x : 入力(データ数, 1)\n",
        "\n",
        "        Wx, Wh = self.params\n",
        "        h_prev = self.h_prev\n",
        "\n",
        "        t = (い)\n",
        "\n",
        "        # 活性化関数は恒等写像関数とする\n",
        "        h_next = t\n",
        "\n",
        "        # 隠れ層の状態を保存\n",
        "        self.prev = (う)\n",
        "\n",
        "        return h_next\n",
        "\n",
        "\"\"\"\n",
        "(あ)・・・h0\n",
        "(い)・・・np.dot(h_prev, Wh) + np.dot(x, Wx)\n",
        "(う)・・・h_next\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XI4y3MSrF358"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKIqBs7AF9Kn"
      },
      "source": [
        "# Section2:LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MC3CD-f-GDF4"
      },
      "source": [
        "**まとめ**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCY-ai-gGHNZ"
      },
      "source": [
        "RNNの課題として、時系列を遡れば遡るほど、勾配が消失する。要するに、長い時系列の学習が困難であること。\n",
        "\n",
        "勾配消失の解決する方法は、構造自体を変えて解決する。要するにLSTMネットワークにするということ。\n",
        "\n",
        "LSTM(Long Short-Term Memory)・・・短期記憶を長期に渡って活用することができる。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnw5vDQdNLz3"
      },
      "source": [
        "**実装演習結果**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vv4NnaSlNLO-"
      },
      "source": [
        "# LSTMクラス実装\n",
        "class LSTM:\n",
        "    def __init__(self, Wx, Wh, b):\n",
        "        self.params = [Wx, Wh, b]\n",
        "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
        "        self.cache = None\n",
        "\n",
        "    def forward(self, x, h_prev, c_prev):\n",
        "        Wx, Wh, b = self.params\n",
        "        N, H = h_prev.shape\n",
        "\n",
        "        A = np.dot(x, Wx) + np.dot(h_prev, Wh) + b\n",
        "        # slice\n",
        "        f = A[:, :H]\n",
        "        g = A[:, H:2*H]\n",
        "        i = A[:, 2*H:3*H]\n",
        "        o = A[:, 3*H:]\n",
        "\n",
        "        f = sigmoid(f)\n",
        "        g = np.tanh(g)\n",
        "        i = sigmoid(i)\n",
        "        o = sigmoid(o)\n",
        "\n",
        "        c_next = f * c_prev + g * i\n",
        "        h_next = o * np.tanh(c_next)\n",
        "\n",
        "        self.cache = (x, h_prev, c_prev, i, f, g, o, c_next)\n",
        "        return h_next, c_next"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfpUocZHKaaK"
      },
      "source": [
        "**確認テスト**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8Mf5m7lF6GM"
      },
      "source": [
        "def gradient_clipping(grad, threshold):\n",
        "    \"\"\"\n",
        "    grad:  gradient\n",
        "    \"\"\"\n",
        "    norm = np.linalg.norm(grad)\n",
        "    rate = threshold / norm\n",
        "    if rate < 1:\n",
        "        return (あ)\n",
        "    return grad    \n",
        "\n",
        "# (あ)・・・gradient * rate\n",
        "# 解説・・・勾配のノルムがしきい値より大きいときは、勾配のノルムをしきい値に正規化するので、クリッピングした勾配は、\n",
        "#        勾配＊(しきい値/勾配ノルム)と計算される。つまり、gradient * rateである。 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQZlsKrdOFQ0"
      },
      "source": [
        "**関連記事**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plo3W2onUvxl"
      },
      "source": [
        "RNNは1時刻前のリカレント層の状態を次のリカレント層へ伝播することにより、そのデータにおける文脈に相当するものを保持する。ただし、このRNNだと、入力された情報の影響が長期に及ぶ場合と短期にしか及ばない場合を区別できないという課題がある。この課題を解決しようとしたモデルが(あ)であり、状態を保存するメモリセルと、メモリを効率的に扱うためのゲートが導入されている。\n",
        "\n",
        "(あ)・・・LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBmXO9lQQXR5"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFhT2bfJQg8-"
      },
      "source": [
        "# Section3:GRU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9x7zt9oQn8O"
      },
      "source": [
        "**まとめ**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHqfIkIuQrS2"
      },
      "source": [
        "GRU(Geted Recurrent Unit)・・・従来のLSTMでは、パラメータが多数存在していたため、計算負荷が大きかった。しかし、GRUでは、そのパラメータを大幅に削減し、精度は同等または、それ以上が望める構造である。つまりは計算負荷が低い構造になっている。\n",
        "\n",
        "LSTMとGRUのどちらを使えばよいのかというと、文献によるとタスクやハイパーパラメータの調整によって、使い分けるとよいとのことです。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJb7tfitCyWo"
      },
      "source": [
        "**実装演習結果**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2m23iQPMCxRg"
      },
      "source": [
        "# GRUクラス実装\n",
        "class GRU:\n",
        "    def __init__(self, Wx, Wh, b):  \n",
        "\n",
        "        self.params = [Wx, Wh, b]  \n",
        "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]  ###\n",
        "        self.cache = None\n",
        "\n",
        "    def forward(self, x, h_prev):\n",
        "        Wx, Wh, b = self.params\n",
        "        H = Wh.shape[0]\n",
        "        Wxz, Wxr, Wxh = Wx[:, :H], Wx[:, H:2 * H], Wx[:, 2 * H:]\n",
        "        Whz, Whr, Whh = Wh[:, :H], Wh[:, H:2 * H], Wh[:, 2 * H:]\n",
        "        bz, br, bh = b[:H], b[H:2 * H], b[2 * H:]  \n",
        "\n",
        "        z = sigmoid(np.dot(x, Wxz) + np.dot(h_prev, Whz) + bz)\n",
        "        r = sigmoid(np.dot(x, Wxr) + np.dot(h_prev, Whr) + br)\n",
        "        h_hat = np.tanh(np.dot(x, Wxh) + np.dot(r*h_prev, Whh) + bh)\n",
        "        h_next = (1-z) * h_prev + z * h_hat\n",
        "\n",
        "        self.cache = (x, h_prev, z, r, h_hat)\n",
        "\n",
        "        return h_next"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyRf3ScaDFne"
      },
      "source": [
        "**確認テスト**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2phH46soE0JK"
      },
      "source": [
        "def gru(x, h, W_r, U_r, W_z, U_z, W, U):\n",
        "    \"\"\"\n",
        "    x: inputs, (batch_size, input_size)\n",
        "    h: outputs at the previous time step, (batch_size, state_size)\n",
        "    W_r, U_r: weights for reset gate\n",
        "    U, W: weights for new state\n",
        "    \"\"\"\n",
        "    # ゲートを計算\n",
        "    r = _sigmoid(x.dot(W_r.T) + h.dot(U_r.T))\n",
        "    z = _sigmoid(x.dot(W_z.T) + h.dot(U_z.T))\n",
        "\n",
        "    # 次の状態を計算\n",
        "    h_bar = np.tanh(x.dot(W.T) + (r * h).dot(U.T))\n",
        "    h_new = (こ)\n",
        "    return h_new\n",
        "\n",
        "# (こ)・・・(1-z) * h + z * h_bar   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXNcxjZxUak7"
      },
      "source": [
        "**関連記事**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8jJYkbxUeZi"
      },
      "source": [
        "Q、シンプルな再起型ニューラルネットワークには、勾配爆発や勾配消失が生じやすいという課題がある。これらの課題を解決するための方法として、LSTMやGRUのようなゲート付き再起型ニューラルネットワークがいくつか提案されている。ゲート付き再起型ニューラルネットワークに関するを述べよ。\n",
        "\n",
        "A、LATM及びGRUにおけるゲートの活性化関数には、通常、シグモイド関数が用いられる。\n",
        "\n",
        "解説・・・ゲート付き再起型ニューラルネットワークに関する問題。ゲートとは、データを通過させる割合を決める機構のことで、その活性化関数には出力が0から1に制約されるシグモイド関数がよく用いられる。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGQPrZsiMB_y"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XayMtjrB_CS5"
      },
      "source": [
        "# Section4:双方向RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTXOXrb0_OAM"
      },
      "source": [
        "**まとめ**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXvvAO6E_QX6"
      },
      "source": [
        "双方向RNNは過去の情報だけでなく、未来の情報を加味することで、精度を向上させるためのモデルです。文章の推敲や機械翻訳に用いられています。LSTMを用いる場合、これまでのLSTMレイヤに加え、逆方向に処理するLDTMレイヤも追加する。このようにLSTMを双方向から処理させるということで、この場合は双方向LSTMと呼ばれる。\n",
        "\n",
        "双方向RNNとは、Bi-directional RNN (BRNN)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5iXTo0BVTwM"
      },
      "source": [
        "**実装演習結果**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bY1Ghvg_VYGC"
      },
      "source": [
        "class TimeBiLSTM:\n",
        "    def __init__(self, Wx1, Wh1, b1,\n",
        "                 Wx2, Wh2, b2, stateful=False):\n",
        "        self.forward_lstm = TimeLSTM(Wx1, Wh1, b1, stateful)\n",
        "        self.backward_lstm = TimeLSTM(Wx2, Wh2, b2, stateful)\n",
        "        self.params = self.forward_lstm.params + self.backward_lstm.params\n",
        "        self.grads = self.forward_lstm.grads + self.backward_lstm.grads\n",
        "\n",
        "    def forward(self, xs):\n",
        "        o1 = self.forward_lstm.forward(xs)\n",
        "        o2 = self.backward_lstm.forward(xs[:, ::-1])\n",
        "        o2 = o2[:, ::-1]\n",
        "\n",
        "        out = np.concatenate((o1, o2), axis=2)\n",
        "        return out\n",
        "\n",
        "    def backward(self, dhs):\n",
        "        H = dhs.shape[2] // 2\n",
        "        do1 = dhs[:, :, :H]\n",
        "        do2 = dhs[:, :, H:]\n",
        "\n",
        "        dxs1 = self.forward_lstm.backward(do1)\n",
        "        do2 = do2[:, ::-1]\n",
        "        dxs2 = self.backward_lstm.backward(do2)\n",
        "        dxs2 = dxs2[:, ::-1]\n",
        "        dxs = dxs1 + dxs2\n",
        "        return dxs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYNPuK1eHZ62"
      },
      "source": [
        "**確認テスト**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGGIZPstLfDy"
      },
      "source": [
        "def bidirectional_rnn_net(xs, W_f, U_f, W_b, U_b, V):\n",
        "    \"\"\"\n",
        "    W_f, U_f: forwad rnn weights, (hidden_size, input_size)\n",
        "    W_b, U_b: backward rnn weights, (hidden_size, input_size)\n",
        "    v: output weights, (output_size, 2*hidden_size)\n",
        "    \"\"\"\n",
        "    xs_f = np.zeros_like(xs)\n",
        "    xs_b = np.zeros_like(xs)\n",
        "    for i, x in enumerate(xs):\n",
        "        xs_f[i] = x\n",
        "        xs_b[i] = x[::-1]\n",
        "    hs_f = _rnn(xs_f, W_f, U_f)\n",
        "    hs_b = _rnn(xs_b, W_b, U_b)\n",
        "    hs = [ (か) for h_f, h_b in zip(hs_f, hs_b)]\n",
        "    ys = hs.dot(V.T)\n",
        "    return ys\n",
        "\n",
        "# (か)・・・np.concatenate([h_f, h_b[::-1], axis=1])\n",
        "# 解説・・・双方向RNNでは、順方向と逆方向に伝播したときの中間層表現を合わせたものが特徴量となる。        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2Asd5LFWZYr"
      },
      "source": [
        "**関連記事**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wX4qPcpCXgWo"
      },
      "source": [
        "(ア)は、過去から未来への方向だけでなく、未来から過去への方向も考慮した再起型ニューラルネットワークです。例えば文章内の文字の穴埋めタスクなど、過去から現在だけでなく、未来から現在までの系列情報を用いる事が有効だと考えられるタスクに用いられる。\n",
        "\n",
        "(ア)・・・双方向RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvc9qLEmMEkF"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6P9y1STpYrOu"
      },
      "source": [
        "# Section5: seq2seq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzzpCLqUY3Vk"
      },
      "source": [
        "**まとめ**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZz_pUiNqde3"
      },
      "source": [
        "Seq2SecはEncoder-Decoderモデルの一種をさす。機械対話や機械翻訳などに使用されている。\n",
        "\n",
        "Encoder RNNはユーザーがインプットしたデータを、単語等に区切って渡す構造。\n",
        "\n",
        "Decoder RNNはシステムがアウトプットデータを、単語等のトークンごとに生成する構造。\n",
        "\n",
        "Seq2Secの課題は一問一答しかできないこと。問に対して文脈も何もなく、ただ応答が行われ続けること。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtFcQMN8HbOY"
      },
      "source": [
        "**実装演習結果**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dK6lwvhZHaMo"
      },
      "source": [
        "def encode(words, E, W, U, b):\n",
        "    \"\"\"\n",
        "    words: sequence words (sentence), one-hot vector, (n_words, vocab_size)\n",
        "    E: word embeding matrix, (embed_size, vocab_size)\n",
        "    W: upward weights, (hidden_size, hidden_size)\n",
        "    U: lateral weights, (hidden_size, embed_size)\n",
        "    b: bias, (hidden_size,)\n",
        "    \"\"\"\n",
        "\n",
        "    hidden_size = W.shape[0]\n",
        "    h = np.zeros(hidden_size)\n",
        "    for w in words:\n",
        "        e = E.dot(w)\n",
        "        h = _actibation(W.dot(e) + U.dot(h) + b)\n",
        "    return h    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hX1LN_yIJWt4"
      },
      "source": [
        "**確認テスト**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvwv4_4FJf0b"
      },
      "source": [
        "Q、seq2seqについて説明せよ。\n",
        "\n",
        "A、RNNを用いたEncoder-Decoderモデルの一種であり、機械翻訳などのモデルに使われる。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_llLUNZKgvE"
      },
      "source": [
        "**参考記事**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-szOX-WLRT9"
      },
      "source": [
        "何らかの系列(記号の列)を受け取り、別の系列へ変換するモデルのことを系列変換モデルという。系列変換モデルは、RNNエンコーダ・デコーダーや(あ)などと呼ばれることもある。\n",
        "\n",
        "(あ)・・・seq2seq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvrBslbUMHr_"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_z4ncARNEAV"
      },
      "source": [
        "# Section6:Word2vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cw0s9_y1NPPI"
      },
      "source": [
        "**まとめ**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eT7rDO0GPFOh"
      },
      "source": [
        "Word2vecは、周囲の単語のコンテキストを学習して単語の類似度を数学的に検出できる。例えば、それぞれの単語のコンテキストといった特徴量が、離散数値表現のベクトルとしてWord2vecによって生成される。Word2vecはテキストのコーパスを入力として受け取って訓練を行い、出力のモデルとして単語ベクトルや埋め込み表現を生成する。単語の埋め込み表現の中では、意味や関係は空間的にエンコードされる。また、ベクトル演算などの便利な特性が備えられている。\n",
        "\n",
        "・word2vecは推論ベースの手法であり、シンプルな2層のニューラルネットワークで構成される。\n",
        "\n",
        "・推論ベースの手法は、推測することを目標として、その副産物として単語の分散表現を得られる。\n",
        "\n",
        "・CBOWモデルは複数の単語(コンテキスト)から一つの単語(ターゲット)を推測する。\n",
        "\n",
        "・skip-gramモデルは一つの単語(ターゲット)から複数の単語(コンテキスト)を推測する。\n",
        "\n",
        "・word2vecは重みの再学習ができるため、単語の分散表現の更新や追加が効率的に行える。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYCQzJs-QxvP"
      },
      "source": [
        "**実装演習結果**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2qLplJSMzeC"
      },
      "source": [
        "class SimpleCBOW:\n",
        "    def __init__(self, vocab_size, hidden_size):\n",
        "        V, H = vocab_size, hidden_size\n",
        "\n",
        "        # 重みの初期化\n",
        "        W_in = 0.01 * np.random.randn(V, H).astype('f')\n",
        "        W_out = 0.01 * np.random.randn(H, V).astype('f')\n",
        "\n",
        "        # レイヤの生成\n",
        "        self.in_layer0 = MatMul(W_in)\n",
        "        self.in_layer1 = MatMul(W_in)\n",
        "        self.out_layer = MatMul(W_out)\n",
        "        self.loss_layer = SoftmaxWithLoss()\n",
        "\n",
        "        # すべての重みと勾配をリストにまとめる\n",
        "        layers = [self.in_layer0, self.in_layer1, self.out_layer]\n",
        "        self.params, self.grads = [], []\n",
        "        for layer in layers:\n",
        "            self.params += layer.params\n",
        "            self.grads += layer.grads\n",
        "\n",
        "        # メンバ変数に単語の分散表現を設定\n",
        "        self.word_vecs = W_in"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5LIetRXN5s5"
      },
      "source": [
        "**確認テスト**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAZd_DNZN-FB"
      },
      "source": [
        "ニューラルネットワークによる学習を通して、単語の分散表現を得るためのツールとして(あ)がある。(あ)には、単語の分散表現を学習する方法として、CBOWとskip-gramの2つのニューラルネットワークが実装されている。\n",
        "\n",
        "(あ)・・・word2vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfpO57h77o1m"
      },
      "source": [
        "**関連記事**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGHmzQkY7sGt"
      },
      "source": [
        "CBOWは(あ)から(い)を予測するのに対して、skip-gramは(い)から(あ)を予測する。CBOW及びskip-gramはいずれも入力層の重み$W_{in}$と出力層側の重み$W_{out}$をパラメータとして持つが、一般に(う)を単語埋め込み行列として利用する。\n",
        "\n",
        "(あ)・・・周辺単語\n",
        "\n",
        "(い)・・・対象となる1単語\n",
        "\n",
        "(う)・・・$W_{in}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymUBO4a_-JzK"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRE1DBVB-Sm2"
      },
      "source": [
        "# Section7:Attention Mechanism"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mp-QONT-EXIY"
      },
      "source": [
        "**まとめ**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CJgqr1m-SeL"
      },
      "source": [
        "Attention Mechanism (注意機構) Attentionと略記される。入力と出力のどの単語が関連しているのかの関連度を学習する仕組み。\n",
        "\n",
        "sec2secの問題は長い文章への対応が難しいことでした。2単語でも100単語でも、固定次元ベクトルの中に入力しなければならなかった。文章が長くなるほどそのシーケンスの内部表現の次元も大きくなっていく仕組みを可能にしたのがAttention Mechanismである。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZZKAtjRGqG8"
      },
      "source": [
        "**実装演習結果**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umSfONzRGyzZ"
      },
      "source": [
        "class Attention Mechanism:\n",
        "    def __init__(self):\n",
        "        self.params, self.grads = [], []\n",
        "        self.attention_weight_layer = AttentionWeight()\n",
        "        self.weight_sum_layer = WeightSum()\n",
        "        self.attention_weight = None\n",
        "    \n",
        "    def forward(self, hs, h):\n",
        "        a = self.attention_weight_layer.forward(hs, h)\n",
        "        out = self.weight_sum_layer.forward(hs, a)\n",
        "        self.attention_weight = a\n",
        "        return out\n",
        "    \n",
        "    def backward(self, dout):\n",
        "        dhs0, da = self.weight_sum_layer.backward(dout)\n",
        "        dhs1, dh = self.attention_weight_layer.backward(da)\n",
        "        dhs = dhs0 + dhs1\n",
        "        return dhs, dh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb0CPo8I-SbQ"
      },
      "source": [
        "**確認テスト**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpV2lGhgEbev"
      },
      "source": [
        "RNNとword2vec、seq2seqとAttention Mechanismの違いは何か。\n",
        "\n",
        "RNN・・・時系列データの処理に適したモデル。\n",
        "\n",
        "word2vec・・・単語の分散表現ベクトルを得る手法。\n",
        "\n",
        "seq2seq・・・1つの時系列データから別の時系列データを得る手法。\n",
        "\n",
        "Attention Mechanism・・・時系列データの中身のそれぞれに重みを付ける手法。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccYa665sIUh4"
      },
      "source": [
        "**関連記事**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJOPCGTuIXyL"
      },
      "source": [
        "ニューラルネットワークにおいて、何らかの特徴があったときに、その特徴のどこを重視すればよいかを学習する機構のことをアテンションという。\n",
        "・ソフトアテンションは、ソフトマックス関数などで確率分布を求め、その確率分布を用いて重み付き平均を得る方法。\n",
        "\n",
        "・ハードアテンションは、ソフトマックス関数などで確率分布を求め、その確率分布に従って抽出された1点だけを得る方法。\n",
        "\n",
        "・2017年に提案されたTransformerという自然言語処理向けのモデルでは、ソースターゲットアテンションやセルフアテンションなどの機構が用いられる。\n",
        "\n",
        "・アテンションはRNNで用いられている機構だが、CNNでも用いることができる。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmyYIO61LztM"
      },
      "source": [
        " ---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_B3HA8iL5Or"
      },
      "source": [
        "# **深層学習day4**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaIzzcVTL-cZ"
      },
      "source": [
        "# Section1:強化学習"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYdLQM5MMQBs"
      },
      "source": [
        "**まとめ**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xvm9vuFgaeVH"
      },
      "source": [
        "強化学習とは、長期的に報酬を最大化できるように、環境の中で行動を選択できるエージェントを作ることを目標とする機械学習の一分野です。強化学習は、行動の結果として与えられる利益(報酬)をもとに、行動を決定する原理を改善していく仕組みです。\n",
        "\n",
        "強化学習では、エージェントとよばれるものが、環境の状況に応じて行動を選択し、その行動によって環境が変化するというのが基本的な枠組み。環境の変化によって、エージェントは何らかの報酬を得る。強化学習のでの目的は、より良い報酬が得られるようにエージェントの行動指針を決めるという点にある。\n",
        "\n",
        "(あ)は、サンプル収益を平均化することに基づいて強化学習問題を解く方法である。現時点の方策πを用いてエピソードを生成し、その結果を用いて価値観数と方策を改善する。これを繰り返す。\n",
        "\n",
        "(い)は、目標の価値と現在の価値のずれを修正していくことによって、価値観数を推定する方法である。\n",
        "\n",
        "(あ)・・・モンテカルロ法\n",
        "\n",
        "(い)・・・TD学習\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnvrelJdpfzO"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fi9V4ztxplxs"
      },
      "source": [
        "# Section2:AlqhaGo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVaTTEPYpvT4"
      },
      "source": [
        "**まとめ**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulZaq590pyEc"
      },
      "source": [
        "AlphaGoの学習\n",
        "\n",
        "1、教師あり学習によるRollOutPolicyとPolicyNetの学習\n",
        "\n",
        "2、強化学習によるPolicyNetの学習\n",
        "\n",
        "3、強化学習によるValueNetの学習\n",
        "\n",
        "教師あり学習フェーズSL policy(Supervised learning of policy networks)の作成では、上級者の手を学習させる。\n",
        "\n",
        "強化学習フェーズRL policy(Reinforcement learning of policy networks)の作成、ではpolicy network同士を戦わせることでより良い手を打つ強化学習policy network(RL policy)を作ることを目的とする。\n",
        "\n",
        "先読みを組み込むために勝敗の評価関数value functionを設け、value network(Reinforcement learning of value networks)の作成する。\n",
        "\n",
        "囲碁はこれまでAIにとってとても難しいゲームだとみなされてきた。それは探索範囲がとても広いことと、盤面の評価が難しいからでした。\n",
        "\n",
        "AlphaGoのアプローチは、盤面の評価のためのvalue networkと、手を選ぶためのpolicy networkを用いる。これらDeep Neural Networkは、人間の打ち手を用いた教師付き学習と、自分同士の対戦による強化学習をうまく組み合わせたもの。 このneural networkは、先読みの探索を行わずとも、最先端の他のモンテカルロ木探索を用いた囲碁ソフト(これらは自分自身と戦うことで何千もの先読みを行う)に匹敵した能力を持つ。\n",
        "\n",
        "同様に、モンテカルロ木探索とvalueおよびpolicy netwrokを組み合わせた新しい探索方法を提案する。 このアルゴリズムを使うことによって、AlphaGoはほかの囲碁のプログラムに99.8%勝利できるようになった。そしてヨーロッパチャンピオンに5戦5勝をおさめた。 19路の囲碁においてコンピュータプログラムが人間のプロを負かすという、これまで何十年もかかると言われて来た、偉業を達成できたのはこれが初めてである。\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRvcjZgR7BYI"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JN6jOL4k7DVV"
      },
      "source": [
        "# Section3:軽量化・高速化技術"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lDI8ArB7Mf8"
      },
      "source": [
        "**まとめ**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VR3CJEuj7PYD"
      },
      "source": [
        "分散深層学習\n",
        "\n",
        "・深層学習は多くのデータを使用したり、パラメータ調整のために多くの時間をしようしたりするため、高速な計算が求められる。\n",
        "\n",
        "・複数の計算資源(ワーカー)を使用し、並列的にニューラルネットを構成することで、効率の良い学習を行いたい。\n",
        "\n",
        "・データ並列化、モデル並列化、GPUによる高速技術は不可欠である。\n",
        "<br>  \n",
        "深層学習において、多数の計算機に処理を分散させて学習を行うことを分散深層学習という。分散深層学習のアプローチには、データ並列(data parallelism)とモデル並列(model parallelism)がある。\n",
        "データ並列では、親モデルをコピーしたｎ個のレプリカを(子モデル)を各GPUワーカーに配置し、異なるバッチを各GPUワーカーに供給する。各GPUワーカーは順伝播と逆伝播を行い、算出した勾配をパラメータターバに送る。パラメータサーバでは、各GPUワーカーから受け取った勾配を用いてパラメータを更新し、更新されたパラメータを各GPUワーカーに送る。\n",
        "データ並列の方式は、パラメータ更新の仕方によって同期型と非同期型に分けられる。同期型の特徴として、すべてのGPUワーカーが勾配を計算してから平均勾配を取るため、GPU間に性能の差があると無駄が生じることが挙げられる。また、非同期型の特徴として、あるGPUワーカーが勾配を計算している間に、パラメータ更新が行われることがあるため、更新時間は最遅GPUワーカーに依存せず、一般に同期型よりもスループットは高い。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gttKcraHr52"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uYusP6WHvCD"
      },
      "source": [
        "# Section4:応用モデル"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExmezqX8H11_"
      },
      "source": [
        "**まとめ**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gn6dgW8dXgCf"
      },
      "source": [
        "・MobileNet\n",
        "\n",
        "モバイル端末の高機能化により、高い演算能力を必要とするアプリの実行が可能となってきた。DeepLearningの応用としてモバイルデバイスの活用が考えられるが、モバイル上に実装するには計算量がボトルネックとなる。その多くの計算量は各層の中でも特に畳込み層における畳込み演算の計算量が大部分を占めることから、畳込み演算を高速化することが、モバイル上でDeepLearningを実装する上で重要となる。そこでMobileNetでDepthwizeConvolutionとPointwizeConvolutionの組み合わせで組み込み演算を軽量化し、計算量を減らすことができる。\n",
        "<br>  \n",
        "・DenseNet\n",
        "\n",
        "あるブロック内の畳み込み層は、そのブロック内ですでに作られた特徴マップすべてをチャンネル方向に結合したものを入力することで、ショートカット結合の効果に加えて、少ないパラメータで性能向上を実現した。DenseNetはショートカットを持っている点ではResNetと同じだが、ResNetのようにショートカットされた特徴マップを足し合わせるのではなく、特徴マップをチャンネル方向に結合する。さらに、そのショートカット結合は、あるブロック内ですでに作られた特徴マップすべてを対象とする。\n",
        "<br>  \n",
        "・Batch Norm Layer\n",
        "\n",
        "各レイヤーへのインプットについて、ミニバッチごとに平均と分散を求めインプットを正規化する。そしてパラメータにより、もう一度平均と分散をシフトする。Batch Normalizaionはニューラルネットワークにおいて学習時間の短縮や初期値への依存低減、過学習の抑制などの効果がある。問題点はBatch Sizeが小さい条件下では、学習が収束しないことがある。データセット全体の平均・分散ではなく、ミニバッチごとに平均・分散を計算するため、ミニ・バッチが小さい場合、平均・分散が不安定になる。そして再帰的ニューラルネットワークに適用するのが難しい。再帰的ニューラルネットワークでは、各サンプルごとに文章の長さが違い、学習データよりも長い文章がテストデータにある場合、適用が簡単ではありません。\n",
        "<br>  \n",
        "・Layer Norm\n",
        "Layer Normalizationでは、1つのサンプルにおける各レイヤーの隠れ層の値の平均・分散で正規化する。N個のサンプルのうち1つに注目し、H ＊ W ＊ Cの全てのピクセルが正規化の単位になる。RGBの3チャンネルのサンプルがN個の場合は、あるサンプルを取り出し、全てのチャンネルの平均と分散を求め正規化を実施する。そして、特徴マップごとに正規化された特徴マップを出力します。ミニバッチを使用しないためBach Nomeでの問題がクリアできると考えられる。\n",
        "<br>  \n",
        "・Instance Nome\n",
        "各サンプルの各チャンネルごとに正規化するので、ネットワークが元画像のコントラストに依存しない学習をすることができるため、スタイル変換などのタスクに適している。\n",
        "<br>  \n",
        "・WaveNet\n",
        "Aaron van den Oord et al,2016らにより提案。WeveNetは、PixelCNNアーキテクチャに基づく音声生成モデルある。畳み込みニューラルネットワークでモデル化したもの。WaveNetでは、コーザル畳み込みとダイレクト畳み込みを組み合わせたダイレクト・コーザル畳み込みを用いる。コーザル畳み込みは、過去の時刻スッテップだけを用いて畳み込みを行う方法であり、少ない階層で受容野を広くできるという特徴がある。ダイレクト畳み込みは、少ないパラメータで広い範囲を畳み込むことを意図しており、フィルタを適用する入力データの場所を数ステップずつスキップし、フィルタをその長さに比べて長い領域に適用する。\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WvG9uKP-YbE"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uhtxrja0pmCI"
      },
      "source": [
        "# Section5:Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6CFBLMLpzuJ"
      },
      "source": [
        "**まとめ**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgf77BqJp9FP"
      },
      "source": [
        "Transformerが提案された2017年12月の論文、Attention Is All You NeedのそのTransformerの内容は、RNNを使用しない。必要なのはAttentionだけ。当時のSOTAをはるかに少ない計算量で実現できた。英仏(3600万文)の学習を8GPUで3.5日で完了できた。\n",
        "\n",
        "翻訳タスクにおいて、Seq2seq(RNNベースEncoder-Decoderモデル)よりも、高速で精度が高い。\n",
        "RNNもCNNも使わずに Attentionのみを使用したEncoder-Decoderモデルで計算量も精度も改善した。さらには並列計算可能で訓練時間が削減できる。そして、ransformerは他のタスクにも汎用性が高い。\n",
        "\n",
        "Transformerの内部には、いくつものアテンション機構が配置されている。それらアテンション機構の基本モジュールは、スケール・ドットプロダクト・アテンションと呼ばれている。複数個のスケール・ドットプロダクト・アテンションを並列に配置したものをマルチヘッド・アテンションという。マルチヘッド・アテンションはエンコーダ、デコーダの両方で使用される。エンコーダにおけるマルチヘッド・アテンションではquetyとkeyとvalueは、すべて最初のエンコーダ出力から伝わってくる。このアテンションのことをセルフ・アテンションという。デコーダにおけるマルチヘッド・アテンションはセルフ・アテンションであるが、ここでは、予測すべき単語の情報が予測時に利用されないようにするためにマスクが掛けられる。マスクが掛けられた場所の値は、ソフトマックス関数に入力される前に -∞ に置き換えられる。デコーダの入力から見て2つ目のマルチヘッド・アテンションでは、keyとvalueはエンコーダ、queryはデコーダから伝わってくる。Transformerには、再帰的な処理や畳み込みが存在しないため、何らかの方法によって。系列の順序に関する情報を考慮しなければならない。その役割を担っているのが、ポジショナル・エンコーディングである。ポジショナル・エンコーディングは単語の順序に関する情報が埋め込まれたベクトルであり、単語埋め込みベクトルに加えられる。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5QjGflD-cYL"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AFYhmu2-faI"
      },
      "source": [
        "# Section6:物体検知・セグメンテーション"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0iP5ArI-s36"
      },
      "source": [
        "**まとめ**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNS4V1ne-yju"
      },
      "source": [
        "物体検出\n",
        "\n",
        "ある画像中における物体の位置を検出し、その物体に対応するクラスを予測するタスクである。物体現出における教師データには、対象となる物体が含まれる矩形領域を示すバウンディングボックスとそれに対応するクラスを用意する必要がある。このような教師データを用いて、物体検出モデルを作成したあとに実際に予測をさせると、同一物体に対して複数のバウンディングボックスが検出されることがある。これを防ぐために各バウンディングボックスに対応する信頼度スコアが最も高いものだけを採用する。これを、非最大値抑制と呼ぶ。非最大値抑制によって決定されたバウンディングボックスと教師データのバウンディングボックスとの一致度を計る指標として、IoUがある。IoUを使ってあるクラスに対する一致度を計る指標に、AP(Average Precision)がある。\n",
        "<br>  \n",
        "セマンティックセグメンテーション\n",
        "\n",
        "ピクセルごとにクラス分類問題を解くことで、1枚の画像中に含まれる複数の物体に対し、それぞれが存在する領域に対応するクラスを出力するタスクである。セマンティックセグメンテーションをCNNを用いて実現する場合、ピクセルごとに分類問題を解くため、いくつかのピクセルが独立して異なるクラスに割り当てられてしまう問題がある。この場合、条件付き確率場による後処理を施すことで精度向上が期待できる。セマンティックセグメンテーションにおいて、モデルの性能は、予測された領域とラベルとして与えられた領域の重複度によって評価されることが多い。重複度を図る指標のひとつとしてIoUが考えられるが、IoUは2つの領域の面積の差が大きいほど値が小さく評価されてしまう欠点がある。そこで、IoUの分母を2つの領域の面積の平均値に置き換えたDice係数が用いられる。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Kr7CgisHplq"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHFUdWLPkgHk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}